@book{book_muller,
	author = {Müller, Meinard},
	year = {2015},
	month = {01},
	pages = {},
	title = {Fundamentals of Music Processing},
	isbn = {978-3-319-21944-8},
	doi = {10.1007/978-3-319-21945-5}
}
@article{poulincharronnat:hal-01985213,
	TITLE = {{Les interactions entre les traitements de la musique et du langage}},
	AUTHOR = {Poulin-Charronnat, B{\'e}n{\'e}dicte and Perruchet, Pierre},
	URL = {https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01985213},
	JOURNAL = {{La Lettre des Neurosciences}},
	VOLUME = {58},
	PAGES = {24-26},
	YEAR = {2018},
	KEYWORDS = {Musique ; Langage},
	HAL_ID = {hal-01985213},
	HAL_VERSION = {v1},
}
@inproceedings{keller:hal-03279850,
	TITLE = {{Techniques de traitement automatique du langage naturel appliqu{\'e}es aux repr{\'e}sentations symboliques musicales}},
	AUTHOR = {Keller, Mikaela and Akesbi, Kamil and Moreira, Lorenzo and Bigo, Louis},
	URL = {https://hal.archives-ouvertes.fr/hal-03279850},
	BOOKTITLE = {{JIM 2021 - Journ{\'e}es d'Informatique Musicale}},
	ADDRESS = {Virtual, France},
	YEAR = {2021},
	MONTH = Jul,
	PDF = {https://hal.archives-ouvertes.fr/hal-03279850/file/keller_et_al.pdf},
	HAL_ID = {hal-03279850},
	HAL_VERSION = {v1},
}
@inproceedings{Jiang2020DiscoveringMR,
	title={Discovering Music Relations with Sequential Attention},
	author={Junyan Jiang and Gus Xia and Taylor Berg-Kirkpatrick},
	booktitle={NLP4MUSA},
	year={2020}
}
@article{article1,
	author = {Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and Kirchhoff, Holger and Klapuri, Anssi},
	year = {2013},
	month = {12},
	pages = {},
	title = {Automatic music transcription: Challenges and future directions},
	volume = {41},
	journal = {Journal of Intelligent Information Systems},
	doi = {10.1007/s10844-013-0258-3}
}
@unknown{article2,
	author = {Malatji, Moshekwa},
	year = {2020},
	month = {10},
	pages = {},
	title = {Automatic Music Transcription for Two Instruments based Variable Q-Transform and Deep Learning methods},
	doi = {10.13140/RG.2.2.28675.94249}
}
@ARTICLE{8350302,
	author={Wu, Chih-Wei and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason and Müller, Meinard and Lerch, Alexander},
	journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	title={A Review of Automatic Drum Transcription},
	year={2018},
	volume={26},
	number={9},
	pages={1457-1483},
	doi={10.1109/TASLP.2018.2830113}
}
@inproceedings{foscarin:hal-01988990,
	TITLE = {{A Parse-based Framework for Coupled Rhythm Quantization and Score Structuring}},
	AUTHOR = {Foscarin, Francesco and Jacquemard, Florent and Rigaux, Philippe and Sakai, Masahiko},
	URL = {https://hal.inria.fr/hal-01988990},
	BOOKTITLE = {{MCM 2019 - Mathematics and Computation in Music}},
	ADDRESS = {Madrid, Spain},
	PUBLISHER = {{Springer}},
	SERIES = {Proceedings of the Seventh International Conference on Mathematics and Computation in Music (MCM 2019)},
	VOLUME = {Lecture Notes in Computer Science},
	YEAR = {2019},
	MONTH = Jun,
	DOI = {10.1007/978-3-030-21392-3\_20},
	PDF = {https://hal.inria.fr/hal-01988990v2/file/springer12.pdf},
	HAL_ID = {hal-01988990},
	HAL_VERSION = {v2},
}
@techreport{jacquemard:hal-01134096,
  TITLE = {{A Term Rewriting Based Structural Theory of Rhythm Notation}},
  AUTHOR = {Jacquemard, Florent and Donat-Bouillud, Pierre and Bresson, Jean},
  URL = {https://hal.inria.fr/hal-01134096},
  TYPE = {Research Report},
  INSTITUTION = {{ANR-13-JS02-0004-01 - EFFICACe}},
  YEAR = {2015},
  MONTH = Mar,
  KEYWORDS = {antescofo},
  PDF = {https://hal.inria.fr/hal-01134096v3/file/efficace-rr.pdf},
  HAL_ID = {hal-01134096},
  HAL_VERSION = {v3},
}
@inproceedings{jacquemard:hal-01403982,
	TITLE = {{Generating equivalent rhythmic notations based on rhythm tree languages}},
	AUTHOR = {Jacquemard, Florent and Ycart, Adrien and Sakai, Masahiko},
	URL = {https://hal.inria.fr/hal-01403982},
	BOOKTITLE = {{Third International Conference on Technologies for Music Notation and Representation (TENOR)}},
	ADDRESS = {Coro{\~n}a, Spain},
	ORGANIZATION = {{Helena Lopez Palma and Mike Solomon}},
	YEAR = {2017},
	MONTH = May,
	PDF = {https://hal.inria.fr/hal-01403982/file/equiv-rhythm.pdf},
	HAL_ID = {hal-01403982},
	HAL_VERSION = {v1},
}
@conference {2802,
	title = {Study of regularizations and constraints in NMF-based drums monaural separation},
	booktitle = {International Conference on Digital Audio Effects Conference (DAFx-13)},
	year = {2013},
	month = {02/09/2013},
	address = {Maynooth, Ireland},
	abstract = {Drums modelling is of special interest in musical source separation because of its widespread presence in western popular music. Current research has often focused on drums separation without specifically modelling the other sources present in the signal.  This paper presents an extensive study of the use of regularizations and constraints to drive the factorization towards the separation between percussive and non-percussive music accompaniment. The proposed regularizations control the frequency smoothness of the basis components and the temporal sparseness of the gains. We also evaluated the use of temporal constraints on the gains to perform the separation, using both ground truth manual annotations (made publicly available) and automatically extracted transients.  Objective evaluation of the results shows that, while optimal regularizations are highly dependent on the signal, drum event position contains enough information to achieve a high quality separation.},
	url = {http://dafx13.nuim.ie/papers/16.dafx2013_submission_16.pdf},
	author = {Marxer, R. and Janer, J.}
}
@article{SHIBATA2021262,
	title = {Non-local musical statistics as guides for audio-to-score piano transcription},
	journal = {Information Sciences},
	volume = {566},
	pages = {262-280},
	year = {2021},
	issn = {0020-0255},
	doi = {https://doi.org/10.1016/j.ins.2021.03.014},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025521002516},
	author = {Kentaro Shibata and Eita Nakamura and Kazuyoshi Yoshii},
	keywords = {Music transcription, Multipitch detection, Rhythm quantization, Deep neural network, Statistical modelling},
	abstract = {We present an automatic piano transcription system that converts polyphonic audio recordings into musical scores. This has been a long-standing problem of music information processing, and recent studies have made remarkable progress in the two main component techniques: multipitch detection and rhythm quantization. Given this situation, we study a method integrating deep-neural-network-based multipitch detection and statistical-model-based rhythm quantization. In the first part, we conducted systematic evaluations and found that while the present method achieved high transcription accuracies at the note level, some global characteristics of music, such as tempo scale, metre (time signature), and bar line positions, were often incorrectly estimated. In the second part, we formulated non-local statistics of pitch and rhythmic contents that are derived from musical knowledge and studied their effects in inferring those global characteristics. We found that these statistics are markedly effective for improving the transcription results and that their optimal combination includes statistics obtained from separated hand parts. The integrated method had an overall transcription error rate of 7.1% and a downbeat F-measure of 85.6% on a dataset of popular piano music, and the generated transcriptions can be partially used for music performance and assisting human transcribers, thus demonstrating the potential for practical applications.}
@article{harasimjazz,
title={THE JAZZ HARMONY TREEBANK},
author={Harasim, Daniel and Finkensiep, Christoph and Ericson, Petter and O’Donnell, Timothy J and Rohrmeier, Martin}
}
@inproceedings{rohrmeier2020towards,
title={Towards a formalisation of musical rhythm},
author={Rohrmeier, Martin},
booktitle={Proceedings of the 21st Int. Society for Music Information Retrieval Conf},
year={2020}
}
@article{first_one,
title={Perception of melodies},
author={Longuet-Higgins, H. C.},
year={1976}
month={1976/10/01},
doi={https://doi.org/10.1038/263646a0},
journal={Nature},
abstract={A computer program has been written which will transcribe a live performance of a classical melody into the equivalent of standard musical notation. It is intended to embody, in computational form, a psychological theory of how Western musicians perceive the rhythmic and tonal relationships between the notes of such melodies.}}