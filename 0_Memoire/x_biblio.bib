@article{MIR_1,
	title="Quelle place pour la science au sein de la musicologie aujourd’hui ?",
	author="Traube, Caroline",
	journal="Circuit",
	volume="24",
	number="2",
	pages="41--49",
	year="2014",
	publisher="Les Presses de l’Université de Montréal",
	doi="https://doi.org/10.7202/1026183ar"
}
@book{book_muller,
	author = {Müller, Meinard},
	year = {2015},
	month = {01},
	pages = {},
	title = {Fundamentals of Music Processing},
	isbn = {978-3-319-21944-8},
	doi = {10.1007/978-3-319-21945-5}
}
@article{poulincharronnat:hal-01985213,
	TITLE = {{Les interactions entre les traitements de la musique et du langage}},
	AUTHOR = {Poulin-Charronnat, B{\'e}n{\'e}dicte and Perruchet, Pierre},
	URL = {https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01985213},
	JOURNAL = {{La Lettre des Neurosciences}},
	VOLUME = {58},
	PAGES = {24-26},
	YEAR = {2018},
	KEYWORDS = {Musique ; Langage},
	HAL_ID = {hal-01985213},
	HAL_VERSION = {v1},
}
@inproceedings{keller:hal-03279850,
	TITLE = {{Techniques de traitement automatique du langage naturel appliqu{\'e}es aux repr{\'e}sentations symboliques musicales}},
	AUTHOR = {Keller, Mikaela and Akesbi, Kamil and Moreira, Lorenzo and Bigo, Louis},
	URL = {https://hal.archives-ouvertes.fr/hal-03279850},
	BOOKTITLE = {{JIM 2021 - Journ{\'e}es d'Informatique Musicale}},
	ADDRESS = {Virtual, France},
	YEAR = {2021},
	MONTH = Jul,
	PDF = {https://hal.archives-ouvertes.fr/hal-03279850/file/keller_et_al.pdf},
	HAL_ID = {hal-03279850},
	HAL_VERSION = {v1},
}
@inproceedings{Jiang2020DiscoveringMR,
	title={Discovering Music Relations with Sequential Attention},
	author={Junyan Jiang and Gus Xia and Taylor Berg-Kirkpatrick},
	booktitle={NLP4MUSA},
	year={2020}
}
@article{future_directions,
	author = {Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and Kirchhoff, Holger and Klapuri, Anssi},
	year = {2013},
	month = {12},
	pages = {},
	title = {Automatic music transcription: Challenges and future directions},
	volume = {41},
	journal = {Journal of Intelligent Information Systems},
	doi = {10.1007/s10844-013-0258-3}
}
@unknown{AMT_for_2_Instru,
	author = {Malatji, Moshekwa},
	year = {2020},
	month = {10},
	pages = {},
	title = {Automatic Music Transcription for Two Instruments based Variable Q-Transform and Deep Learning methods},
	doi = {10.13140/RG.2.2.28675.94249}
}
@ARTICLE{Review_ADT,
	author={Wu, Chih-Wei and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason and Müller, Meinard and Lerch, Alexander},
	journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	title={A Review of Automatic Drum Transcription},
	year={2018},
	volume={26},
	number={9},
	pages={1457-1483},
	doi={10.1109/TASLP.2018.2830113}
}
@inproceedings{foscarin:hal-01988990,
	TITLE = {{A Parse-based Framework for Coupled Rhythm Quantization and Score Structuring}},
	AUTHOR = {Foscarin, Francesco and Jacquemard, Florent and Rigaux, Philippe and Sakai, Masahiko},
	URL = {https://hal.inria.fr/hal-01988990},
	BOOKTITLE = {{MCM 2019 - Mathematics and Computation in Music}},
	ADDRESS = {Madrid, Spain},
	PUBLISHER = {{Springer}},
	SERIES = {Proceedings of the Seventh International Conference on Mathematics and Computation in Music (MCM 2019)},
	VOLUME = {Lecture Notes in Computer Science},
	YEAR = {2019},
	MONTH = Jun,
	DOI = {10.1007/978-3-030-21392-3\_20},
	PDF = {https://hal.inria.fr/hal-01988990v2/file/springer12.pdf},
	HAL_ID = {hal-01988990},
	HAL_VERSION = {v2},
}
@techreport{jacquemard:hal-01134096,
  TITLE = {{A Term Rewriting Based Structural Theory of Rhythm Notation}},
  AUTHOR = {Jacquemard, Florent and Donat-Bouillud, Pierre and Bresson, Jean},
  URL = {https://hal.inria.fr/hal-01134096},
  TYPE = {Research Report},
  INSTITUTION = {{ANR-13-JS02-0004-01 - EFFICACe}},
  YEAR = {2015},
  MONTH = Mar,
  KEYWORDS = {antescofo},
  PDF = {https://hal.inria.fr/hal-01134096v3/file/efficace-rr.pdf},
  HAL_ID = {hal-01134096},
  HAL_VERSION = {v3},
}
@inproceedings{jacquemard:hal-01403982,
	TITLE = {{Generating equivalent rhythmic notations based on rhythm tree languages}},
	AUTHOR = {Jacquemard, Florent and Ycart, Adrien and Sakai, Masahiko},
	URL = {https://hal.inria.fr/hal-01403982},
	BOOKTITLE = {{Third International Conference on Technologies for Music Notation and Representation (TENOR)}},
	ADDRESS = {Coro{\~n}a, Spain},
	ORGANIZATION = {{Helena Lopez Palma and Mike Solomon}},
	YEAR = {2017},
	MONTH = May,
	PDF = {https://hal.inria.fr/hal-01403982/file/equiv-rhythm.pdf},
	HAL_ID = {hal-01403982},
	HAL_VERSION = {v1},
}
@conference {2802,
	title = {Study of regularizations and constraints in NMF-based drums monaural separation},
	booktitle = {International Conference on Digital Audio Effects Conference (DAFx-13)},
	year = {2013},
	month = {02/09/2013},
	address = {Maynooth, Ireland},
	abstract = {Drums modelling is of special interest in musical source separation because of its widespread presence in western popular music. Current research has often focused on drums separation without specifically modelling the other sources present in the signal.  This paper presents an extensive study of the use of regularizations and constraints to drive the factorization towards the separation between percussive and non-percussive music accompaniment. The proposed regularizations control the frequency smoothness of the basis components and the temporal sparseness of the gains. We also evaluated the use of temporal constraints on the gains to perform the separation, using both ground truth manual annotations (made publicly available) and automatically extracted transients.  Objective evaluation of the results shows that, while optimal regularizations are highly dependent on the signal, drum event position contains enough information to achieve a high quality separation.},
	url = {http://dafx13.nuim.ie/papers/16.dafx2013_submission_16.pdf},
	author = {Marxer, R. and Janer, J.}
}
@article{SHIBATA2021262,
	title = {Non-local musical statistics as guides for audio-to-score piano transcription},
	journal = {Information Sciences},
	volume = {566},
	pages = {262-280},
	year = {2021},
	issn = {0020-0255},
	doi = {https://doi.org/10.1016/j.ins.2021.03.014},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025521002516},
	author = {Kentaro Shibata and Eita Nakamura and Kazuyoshi Yoshii},
	keywords = {Music transcription, Multipitch detection, Rhythm quantization, Deep neural network, Statistical modelling},
	abstract = {We present an automatic piano transcription system that converts polyphonic audio recordings into musical scores. This has been a long-standing problem of music information processing, and recent studies have made remarkable progress in the two main component techniques: multipitch detection and rhythm quantization. Given this situation, we study a method integrating deep-neural-network-based multipitch detection and statistical-model-based rhythm quantization. In the first part, we conducted systematic evaluations and found that while the present method achieved high transcription accuracies at the note level, some global characteristics of music, such as tempo scale, metre (time signature), and bar line positions, were often incorrectly estimated. In the second part, we formulated non-local statistics of pitch and rhythmic contents that are derived from musical knowledge and studied their effects in inferring those global characteristics. We found that these statistics are markedly effective for improving the transcription results and that their optimal combination includes statistics obtained from separated hand parts. The integrated method had an overall transcription error rate of 7.1% and a downbeat F-measure of 85.6% on a dataset of popular piano music, and the generated transcriptions can be partially used for music performance and assisting human transcribers, thus demonstrating the potential for practical applications.}
@article{harasimjazz,
title={THE JAZZ HARMONY TREEBANK},
author={Harasim, Daniel and Finkensiep, Christoph and Ericson, Petter and O’Donnell, Timothy J and Rohrmeier, Martin}
}
@inproceedings{rohrmeier2020towards,
title={Towards a formalisation of musical rhythm},
author={Rohrmeier, Martin},
booktitle={Proceedings of the 21st Int. Society for Music Information Retrieval Conf},
year={2020}
}
@article{first_one,
title={Perception of melodies},
author={Longuet-Higgins, H. C.},
year={1976}
month={1976/10/01},
doi={https://doi.org/10.1038/263646a0},
journal={Nature},
abstract={A computer program has been written which will transcribe a live performance of a classical melody into the equivalent of standard musical notation. It is intended to embody, in computational form, a psychological theory of how Western musicians perceive the rhythmic and tonal relationships between the notes of such melodies.}}
@ARTICLE{NO_PDF_ACCESS,
author={Benetos, Emmanouil and Dixon, Simon and Duan, Zhiyao and Ewert, Sebastian},
journal={IEEE Signal Processing Magazine}, 
title={Automatic Music Transcription: An Overview}, 
year={2019},
volume={36},
number={1},
pages={20-30},
doi={10.1109/MSP.2018.2869928}}
@article{adama_1 ,
author = {Kazuyoshi Yoshii, Masataka Goto, Hiroshi G. Okuno},
title = {Automatic Drum Sound Description for Real-World Music Using Template Adaptation and Matching Methods},
year = {2004},
journal = {International Conference on Music Information Retrieval (ISMIR)},
pages = {184-191},
publisher = {ISMIR},
abstract = {This paper presents an automatic description system of drum sounds for real-world musical audio signals. Our system can represent onset times and names of drums by means of drum descriptors defined in the context of MPEG-7. For their automatic description, drum sounds must be identified in such polyphonic signals. The problem is that acoustic features of drum sounds vary with each musical piece and precise templates for them cannot be prepared in advance. To solve this problem, we propose new template-adaptation and template-matching methods. The former method adapts a single seed template prepared for each kind of drums to the corresponding drum sound appearing in an actual musical piece. The latter method then can detect all the onsets of each drum by using the corresponding adapted template. The onsets of bass and snare drums in any piece can thus be identified. Experimental results …}
}
@article{Eronen ,
author={Antti J. Eronen},
title={Musical instrument recognition using ICA-based transform of features and discriminatively trained HMMs},
journal={Seventh International Symposium on Signal Processing and Its Applications, 2003. Proceedings.},
year={2003},
volume={2},
pages={133-136 vol.2}
}
@inproceedings{rythm_tree,
author = {Agon, C. and Haddad, K. and Assayag, G.},
title = {Representation and Rendering of Rhythm Structures},
year = {2002},
isbn = {0769518621},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We propose a format and a set of tools in the rendering ofcomputer musical notation.
The proposed format is not tobe considered as a universal standard. Nevertheless,
it appearsto be an efficient approach to musical notation. Theproposed format might
be thought as a contribution to futureor existing implementations of musical editors.
We willtry to provide general guidelines and schemes that will becompatible with any
type of programming language. Thisprotocol has been implemented in the OpenMusic environmentusing
the CLOS language environment. This paper isan a posteriori generalization of this
implementation.},
booktitle = {Proceedings of the First International Symposium on Cyber Worlds (CW'02)},
pages = {109},
series = {CW '02}
}